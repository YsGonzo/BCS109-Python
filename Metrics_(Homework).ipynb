{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics (Homework).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic8SLv7gaDq_"
      },
      "source": [
        "##Precision\n",
        "* TP / (TP + FP)\n",
        "* Out of all the positives, This gives what percentage was true positive.\n",
        "\n",
        "##recall\n",
        "* TP / (TP + FN)\n",
        "* This shows the percentage of positives correctly labelled. This can be good in certain scenarios such as \"of all the passengers that survived, how many were labeled? A recall above .50 is good for this model.\"\n",
        "\n",
        "##Accuracy\n",
        "* TP + TN / (TP + TN + FP + FN)\n",
        "* A measure of correctly predicted observations to the total observations.\n",
        "This is most applicable with symmetrical datasets that have a near equal amount of false positives and false negatives.\n",
        "\n",
        "---\n",
        "##Confusion matrix\n",
        "* Prediction (Negative/positive) rows and Actual (Negative/Positive) columns, this shows whether something is false positive, false positive, true negative, or false negative.\n",
        "\n",
        "---\n",
        "##Bias\n",
        "* Fits a very focused group of issues (machine learning).\n",
        "\n",
        "##Variance\n",
        "* allows for a model to identify/predict patterns. Model complexity (balance of bias and variance) has an optimal point which is the target.\n",
        "\n",
        "#Tradeoff\n",
        "* The tradeoff can either be a program that is too bias, creating an underfit program for the data. The program can also have too much variance, creating an overfit program for the data.\n",
        "\n",
        "---\n",
        "##train.test.split()\n",
        "* Partitions your dataset, analyzes it and see if it fits with the rest of the data in the dataset. The purpose is to see how the program will fare against data not previously used to train the AI.\n",
        "\n",
        "---\n",
        "A Type 1 is a false positive prediction.\n",
        "\n",
        "A Type 2 Error is a false negative prediction.\n",
        "\n",
        "---\n",
        "#F1 Score\n",
        "* averaged recall and precision \n",
        "* F1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQVrY03uaBvc"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "#Python code for accuracy, precision, recall, and F1\n",
        "#Method provided by sklearn.metrics\n",
        "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}